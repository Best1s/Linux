input {
       kafka {
       id => "pro-kafka"
       bootstrap_servers => "127.0.0.1:9092"
       client_id => "localhostIP"
       group_id => "pro-kafka-localhostIP"
       topics => ["javalog"]
       #auto_offset_reset => "latest"   #当各分区有已提交的offset，从提交的offset开始消费；无offset时，消费新产生的该分区下的数据
       auto_offset_reset => "earliest"  #当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
       consumer_threads => 50
       decorate_events => true
    }
   }
filter {
    json {
  	    source => "message"
  	}
    grok {
        match => { "message" => "%{TIMESTAMP_ISO8601:timestamp}"}
    }
    multiline {
        pattern => "^202"
        negate => true
        what => "previous"
    }
    mutate {
        remove_field => ["offset" ]
    }
  	date {
      	match => ["timestamp","yyyy-MM-dd HH:mm:ss.SSS","ISO8601"]
      	target => "@timestamp"
  	}
}
output {
    if [@metadata][kafka][topic] == "javalog" {
        elasticsearch {
            hosts => ["127.0.0.1:9200"]
            index => "projavalog-%{+YYYY.MM.dd}"
        }
    }
}